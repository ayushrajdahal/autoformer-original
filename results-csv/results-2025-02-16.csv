Setting,seq_len,label_len,pred_len,e_layers,d_layers,factor,train/val/test,time emb,MSE,MAE,RMSE,MAPE,MSPE
Default,96,48,24,2,1,3,3.1.1,, 0.39163053035736084, 0.42184269428253174, 0.6258038878440857, 2.7656383514404297,6443.633301
Sin/Cos Embedding,,,,,,,,sin-cos, 0.3594552278518677, 0.39998331665992737, 0.5995458364486694, 2.523573398590088, 3676.156005859375
Seasonal Embedding,,,,,,,,seasons, 0.38406509160995483, 0.4167793095111847, 0.6197298765182495, 2.852004051208496,7399.407227
Sequence length (+),48,,,,,,,, 0.33535492420196533, 0.3740333020687103, 0.5790983438491821, 2.618772268295288,5807.09375
Sequence length (++),144,,,,,,,, 0.4236143231391907, 0.4419722259044647,0.650856614, 2.9684505462646484,8090.126953
Label length (-),,24,,,,,,, 0.36629003286361694, 0.4013431668281555, 0.6052190065383911, 2.636127233505249,3906.891113
Label length (+),,72,,,,,,, 0.36025798320770264, 0.4075755476951599,0.600214958, 2.670104742050171,4961.282227
Prediction length (-),,,12,,,,,, 0.2716487646102905, 0.34318217635154724, 0.5211993455886841,2.543703794,6600.135742
Prediction length (+),,,48,,,,,, 0.4433427155017853, 0.4466775953769684, 0.6658398509025574, 2.6011407375335693,3308.597656
Prediction length (++),,,72,,,,,, 0.5002577304840088, 0.48369279503822327, 0.7072889804840088,2.943261147,5866.155273
Encoder (-),,,,1,,,,, 0.4075931906700134, 0.4304552376270294, 0.6384302377700806, 2.773420810699463,5345.739746
Encoder (+),,,,3,,,,, 0.37294918298721313,0.41058442, 0.6106956601142883, 2.619987726211548,4684.236328
Decoder (+),,,,,2,,,, 0.36370405554771423, 0.4045509696006775, 0.6030788421630859, 2.5164313316345215, 3108.518310546875
Decoder (++),,,,,3,,,, 0.3729136884212494, 0.40907108783721924, 0.6106665730476379, 2.5870251655578613,4582.200684
2train_1val_2test,,,,,,,2.1.2,, 0.45135730504989624, 0.4500790238380432, 0.6718313097953796, 3.031104803085327,14555.86816
1train_1val_3test,,,,,,,1.1.3,,0.472595215, 0.4642467200756073, 0.6874555945396423, 2.913090705871582,10376.78809
Attention Factor (--),,,,,,1,,, 0.3772331774234772, 0.4133422076702118, 0.6141930818557739, 2.628286600112915,4836.171387
Attention Factor (-),,,,,,2,,, 0.3733721375465393, 0.41233503818511963, 0.6110418438911438, 2.7764103412628174,6391.44873
Attention Factor (+),,,,,,5,,, 0.38794100284576416, 0.41888853907585144, 0.6228491067886353, 2.715535879135132,4060.924316